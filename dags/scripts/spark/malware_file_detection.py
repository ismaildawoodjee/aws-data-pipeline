"""This is one place where data processing or machine learning with Spark could occur. 
A previously trained classification algorithm could perhaps be used to classify the 
new batch of incoming data and predict whether or not the features in there describe 
a malicious file. Additional ML engineering can be done to feed the algorithm with 
new data and also improve its accuracy, but that is out of the scope of this project. 

In this script, I am just selecting some columns that I think might be useful to 
display on a daily dashboard, and will not be doing any machine learning. The
target column (dependent variable) `actually_malicious` is an already classified
column, so we can just pretend the machine learning is already done here.
"""

import sys
from pyspark.sql.functions import *
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Spark job on EMR").getOrCreate()

# sys.argv[1] is the full S3 URI for the input file that Spark on EMR will read from
# this is the CSV file in the `raw` folder on S3
df = spark.read.option("inferSchema", "true").option("header", "true").csv(sys.argv[1])

new_df = df.select(
    "time_received",
    "download_source",
    "top_level_domain",
    "ping_time_to_server",
    "file_size_bytes",
    "executable_code_maybe_present_in_headers",
    "calls_to_low_level_system_libraries",
    "evidence_of_code_obfuscation",
    "threads_started",
    "characters_in_url",
    "actually_malicious",
    "initial_statistical_analysis",
)

# sys.argv[2] is also the full S3 URI for the output destination folder that EMR will write to
# this is going to be the `stage` folder on S3
new_df.write.format("csv").mode("overwrite").save(sys.argv[2])
